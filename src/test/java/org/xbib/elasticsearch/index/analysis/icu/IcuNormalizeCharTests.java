package org.xbib.elasticsearch.index.analysis.icu;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.elasticsearch.common.settings.Settings;
import org.elasticsearch.index.Index;
import org.elasticsearch.test.ESTestCase;
import org.elasticsearch.test.ESTokenStreamTestCase;
import org.xbib.elasticsearch.plugin.bundle.BundlePlugin;

import java.io.Reader;
import java.io.StringReader;

/**
 * ICU normalize char tests.
 */
public class IcuNormalizeCharTests extends ESTokenStreamTestCase {

    public void testNormalize() throws Exception {
        String source = "J√∂rg Prante";
        String resource = "/org/xbib/elasticsearch/index/analysis/icu/icu_normalize.json";
        Settings settings = Settings.builder()
                .loadFromStream(resource, getClass().getResourceAsStream(resource), true)
                .build();
        ESTestCase.TestAnalysis analysis = ESTestCase.createTestAnalysis(new Index("test", "_na_"),
                settings,
                new BundlePlugin(Settings.EMPTY));
        Reader charFilter = analysis.charFilter.get("my_icu_normalizer").create(new StringReader(source));
        StringBuilder sb = new StringBuilder();
        int ch;
        while ((ch = charFilter.read()) != -1) {
            sb.append((char)ch);
        }
        assertEquals("jorg prante", sb.toString());
    }

    public void testFoldingAnalyzer() throws Exception {
        String resource = "/org/xbib/elasticsearch/index/analysis/icu/icu_normalize.json";
        Settings settings = Settings.builder()
                .loadFromStream(resource, getClass().getResourceAsStream(resource), true)
                .build();
        ESTestCase.TestAnalysis analysis = ESTestCase.createTestAnalysis(new Index("test", "_na_"),
                settings,
                new BundlePlugin(Settings.EMPTY));
        Analyzer analyzer = analysis.indexAnalyzers.get("my_icu_analyzer");
        assertTokenStreamContents(analyzer.tokenStream("test", "This is a test"), new String[]{ "this", "is", "a", "test" });
        assertTokenStreamContents(analyzer.tokenStream("test", "Ru√ü"), new String[]{ "russ" });
        assertTokenStreamContents(analyzer.tokenStream("test", "J√∂rg Prante"), new String[] { "jorg", "prante" });
        assertTokenStreamContents(analyzer.tokenStream("test", "ŒúŒÜŒ™ŒüŒ£"), new String[]{  "ŒºŒ±ŒπŒøœÉ" });
        assertTokenStreamContents(analyzer.tokenStream("test", "ŒúŒ¨œäŒøœÇ"), new String[] { "ŒºŒ±ŒπŒøœÉ" });
        assertTokenStreamContents(analyzer.tokenStream("test", "êêñ"), new String[] { "êêæ" });
        assertTokenStreamContents(analyzer.tokenStream("test", "Ô¥≥Ô¥∫Ô∞ß"), new String[] { "ÿ∑ŸÖÿ∑ŸÖÿ∑ŸÖ" });
        assertTokenStreamContents(analyzer.tokenStream("test", "‡§ï‡•ç‚Äç‡§∑"), new String[] { "‡§ï‡§∑" });
        assertTokenStreamContents(analyzer.tokenStream("test", "r√©sum√©"), new String[] { "resume" });
        assertTokenStreamContents(analyzer.tokenStream("test", "re\u0301sume\u0301"), new String[] { "resume" });
        assertTokenStreamContents(analyzer.tokenStream("test", "‡ß≠‡ß¶‡ß¨"), new String[] { "706" });
        assertTokenStreamContents(analyzer.tokenStream("test", "ƒëis is cr√¶zy"), new String[] { "dis", "is", "craezy" });
        assertTokenStreamContents(analyzer.tokenStream("test",  "ELƒ∞F"), new String[] { "elif" });
        assertTokenStreamContents(analyzer.tokenStream("test", "eli\u0307f"), new String[] { "elif" });
    }

    public void testFoldingAnalyzerWithExceptions() throws Exception {
        String resource = "/org/xbib/elasticsearch/index/analysis/icu/icu_normalize.json";
        Settings settings = Settings.builder()
                .loadFromStream(resource, getClass().getResourceAsStream(resource), true)
                .build();
        ESTestCase.TestAnalysis analysis = ESTestCase.createTestAnalysis(new Index("test", "_na_"),
                settings,
                new BundlePlugin(Settings.EMPTY));
        Analyzer analyzer = analysis.indexAnalyzers.get("my_icu_analyzer_with_exceptions");
        TokenStream ts = analyzer.tokenStream("test", "J√∂rg Prante");
        String[] expected = { "j√∂rg", "prante" };
        assertTokenStreamContents(ts, expected);
    }
}
